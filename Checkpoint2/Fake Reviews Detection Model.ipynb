{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0072a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "%matplotlib inline\n",
    "import warnings, string\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46e09e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>['love', 'well', 'made', 'sturdy', 'comfortabl...</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>['love', 'great', 'upgrade', 'original', 'ive'...</td>\n",
       "      <td>love great upgrade original ive mine couple year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>['pillow', 'saved', 'back', 'love', 'look', 'f...</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>['missing', 'information', 'use', 'great', 'pr...</td>\n",
       "      <td>missing information use great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>['nice', 'set', 'good', 'quality', 'set', 'two...</td>\n",
       "      <td>nice set good quality set two month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['love', 'well', 'made', 'sturdy', 'comfortabl...   \n",
       "1  ['love', 'great', 'upgrade', 'original', 'ive'...   \n",
       "2  ['pillow', 'saved', 'back', 'love', 'look', 'f...   \n",
       "3  ['missing', 'information', 'use', 'great', 'pr...   \n",
       "4  ['nice', 'set', 'good', 'quality', 'set', 'two...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  love well made sturdy comfortable love itvery ...  \n",
       "1   love great upgrade original ive mine couple year  \n",
       "2            pillow saved back love look feel pillow  \n",
       "3        missing information use great product price  \n",
       "4                nice set good quality set two month  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CHP1_fakeReviewData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210251cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "      <th>tokens</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>['love', 'well', 'made', 'sturdy', 'comfortabl...</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>['love', 'great', 'upgrade', 'original', 'ive'...</td>\n",
       "      <td>love great upgrade original ive mine couple year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>['pillow', 'saved', 'back', 'love', 'look', 'f...</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>['missing', 'information', 'use', 'great', 'pr...</td>\n",
       "      <td>missing information use great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>['nice', 'set', 'good', 'quality', 'set', 'two...</td>\n",
       "      <td>nice set good quality set two month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['love', 'well', 'made', 'sturdy', 'comfortabl...   \n",
       "1  ['love', 'great', 'upgrade', 'original', 'ive'...   \n",
       "2  ['pillow', 'saved', 'back', 'love', 'look', 'f...   \n",
       "3  ['missing', 'information', 'use', 'great', 'pr...   \n",
       "4  ['nice', 'set', 'good', 'quality', 'set', 'two...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  love well made sturdy comfortable love itvery ...  \n",
       "1   love great upgrade original ive mine couple year  \n",
       "2            pillow saved back love look feel pillow  \n",
       "3        missing information use great product price  \n",
       "4                nice set good quality set two month  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81649454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(review):\n",
    "    nopunc = [char for char in review if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3fc209c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(analyzer=&lt;function text_process at 0x000001EC609D5440&gt;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(analyzer=&lt;function text_process at 0x000001EC609D5440&gt;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(analyzer=<function text_process at 0x000001EC609D5440>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_transformer = CountVectorizer(analyzer=text_process)\n",
    "bow_transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11fecb",
   "metadata": {},
   "source": [
    "## Creating training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "501767f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, x_train, x_test = train_test_split(df['text_'],df['label'],test_size=0.35)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1004f",
   "metadata": {},
   "source": [
    "## Multinomial Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dbee9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.82      0.91      0.86      7017\n",
      "          OR       0.90      0.80      0.84      7076\n",
      "\n",
      "    accuracy                           0.85     14093\n",
      "   macro avg       0.86      0.85      0.85     14093\n",
      "weighted avg       0.86      0.85      0.85     14093\n",
      "\n",
      "Confusion Matrix: [[6372  645]\n",
      " [1435 5641]]\n",
      "Accuracy Score: 0.8524089973745831\n",
      "Model Prediction Accuracy: 85.24%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',MultinomialNB())\n",
    "])\n",
    "pipeline.fit(y_train,x_train)\n",
    "mnb_pred = pipeline.predict(y_test)\n",
    "mnb_pred\n",
    "print('Classification Report:',classification_report(x_test,mnb_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(x_test,mnb_pred))\n",
    "print('Accuracy Score:',accuracy_score(x_test,mnb_pred))\n",
    "print('Model Prediction Accuracy:',str(np.round(accuracy_score(x_test,mnb_pred)*100,2)) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd83119d",
   "metadata": {},
   "source": [
    "\n",
    "## Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cdb42a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.81      0.90      0.85      7017\n",
      "          OR       0.89      0.80      0.84      7076\n",
      "\n",
      "    accuracy                           0.85     14093\n",
      "   macro avg       0.85      0.85      0.85     14093\n",
      "weighted avg       0.85      0.85      0.85     14093\n",
      "\n",
      "Confusion Matrix: [[6297  720]\n",
      " [1450 5626]]\n",
      "Accuracy Score: 0.8460228482225218\n",
      "Model Prediction Accuracy: 84.6%\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',RandomForestClassifier())\n",
    "])\n",
    "pipeline.fit(y_train,x_train)\n",
    "rfc_pred = pipeline.predict(y_test)\n",
    "rfc_pred\n",
    "print('Classification Report:',classification_report(x_test,rfc_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(x_test,rfc_pred))\n",
    "print('Accuracy Score:',accuracy_score(x_test,rfc_pred))\n",
    "print('Model Prediction Accuracy:',str(np.round(accuracy_score(x_test,rfc_pred)*100,2)) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc140f",
   "metadata": {},
   "source": [
    "## Support Vector Machine/Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82371e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.91      0.87      0.89      7017\n",
      "          OR       0.88      0.91      0.90      7076\n",
      "\n",
      "    accuracy                           0.89     14093\n",
      "   macro avg       0.89      0.89      0.89     14093\n",
      "weighted avg       0.89      0.89      0.89     14093\n",
      "\n",
      "Confusion Matrix: [[6108  909]\n",
      " [ 607 6469]]\n",
      "Accuracy Score: 0.8924288653941673\n",
      "Model Prediction Accuracy: 89.24%\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',SVC())\n",
    "])\n",
    "pipeline.fit(y_train,x_train)\n",
    "svc_pred = pipeline.predict(y_test)\n",
    "svc_pred\n",
    "print('Classification Report:',classification_report(x_test,svc_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(x_test,svc_pred))\n",
    "print('Accuracy Score:',accuracy_score(x_test,svc_pred))\n",
    "print('Model Prediction Accuracy:',str(np.round(accuracy_score(x_test,svc_pred)*100,2)) + '%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e78b3",
   "metadata": {},
   "source": [
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5e87f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.89      0.86      0.87      7017\n",
      "          OR       0.86      0.89      0.88      7076\n",
      "\n",
      "    accuracy                           0.88     14093\n",
      "   macro avg       0.88      0.88      0.88     14093\n",
      "weighted avg       0.88      0.88      0.88     14093\n",
      "\n",
      "Confusion Matrix: [[6018  999]\n",
      " [ 759 6317]]\n",
      "Accuracy Score: 0.8752572198964025\n",
      "Model Prediction Accuracy: 87.53%\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf',TfidfTransformer()),\n",
    "    ('classifier',LogisticRegression())\n",
    "])\n",
    "pipeline.fit(y_train,x_train)\n",
    "logi_pred = pipeline.predict(y_test)\n",
    "logi_pred\n",
    "print('Classification Report:',classification_report(x_test,logi_pred))\n",
    "print('Confusion Matrix:',confusion_matrix(x_test,logi_pred))\n",
    "print('Accuracy Score:',accuracy_score(x_test,logi_pred))\n",
    "print('Model Prediction Accuracy:',str(np.round(accuracy_score(x_test,logi_pred)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0caeb",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d092c25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different ML model performances:\n",
      "\n",
      "\n",
      "Logistic Regression Model Accuracy: 87.53%\n",
      "Random Forests Classifier Model Accuracy: 84.6%\n",
      "Support Vector Machines Model Accuracy: 89.24%\n",
      "Multinomial Naive Bayes Model Accuracy: 85.24%\n"
     ]
    }
   ],
   "source": [
    "print('Different ML model performances:')\n",
    "print('\\n')\n",
    "print('Logistic Regression Model Accuracy:',str(np.round(accuracy_score(x_test,logi_pred)*100,2)) + '%')\n",
    "print('Random Forests Classifier Model Accuracy:',str(np.round(accuracy_score(x_test,rfc_pred)*100,2)) + '%')\n",
    "print('Support Vector Machines Model Accuracy:',str(np.round(accuracy_score(x_test,svc_pred)*100,2)) + '%')\n",
    "print('Multinomial Naive Bayes Model Accuracy:',str(np.round(accuracy_score(x_test,mnb_pred)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eff2e275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['naiveBayes_model.pkl']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(logi_pred,'logisticRegre_model.pkl')\n",
    "joblib.dump(svc_pred,'svc_model.pkl')\n",
    "joblib.dump(rfc_pred,'randomForest_model.pkl')\n",
    "joblib.dump(mnb_pred,'naiveBayes_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
